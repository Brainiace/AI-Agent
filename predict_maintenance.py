import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_recall_curve, PrecisionRecallDisplay,
                             f1_score, recall_score, classification_report)
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
import joblib
import numpy as np

# Mathematical Explanation:
# 1. Physics-Informed Feature Engineering:
#    - Power_kW: P = (T * omega) / 9550. Mechanical power is a fundamental indicator
#      of machine load. High power can lead to accelerated wear.
#    - Temp_Diff: Delta_T = T_process - T_air. This represents the internal heat
#      generated by the process, indicating thermal stress and potential cooling issues.
#    - Torque_Wear_Product: T * Wear. This captures the synergistic effect of
#      mechanical stress and degradation, which often triggers "overstrain" failures.
#
# 2. SMOTE (Synthetic Minority Over-sampling Technique):
#    Given the 3.4% failure rate, the model would naturally bias towards 'No Failure'.
#    SMOTE creates synthetic failure cases by interpolating between existing ones,
#    ensuring the decision boundary is informed by the minority class.
#
# 3. GridSearchCV & Random Forest:
#    We optimize hyperparameters (n_estimators, max_depth, min_samples_leaf) to
#    maximize the F1-score, balancing Recall (finding failures) and Precision.
#    We prioritize Recall > 85% to minimize missed failures (False Negatives).

def train_maintenance_model(data_path):
    """
    Performs a clean rebuild of the predictive maintenance model.
    """
    # 1. Data Pipeline
    df = pd.read_csv(data_path)

    # Feature Engineering
    df['Power_kW'] = (df['Torque [Nm]'] * df['Rotational speed [rpm]']) / 9550
    df['Temp_Diff'] = df['Process temperature [K]'] - df['Air temperature [K]']
    df['Torque_Wear_Product'] = df['Torque [Nm]'] * df['Tool wear [min]']

    # Define features and target
    # Exclude non-predictive columns and potential leaks (specific failure types)
    drop_cols = ['UDI', 'Product ID', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']
    X = df.drop(drop_cols, axis=1)
    y = df['Machine failure']

    # Encode 'Type' (L, M, H)
    le = LabelEncoder()
    X['Type'] = le.fit_transform(X['Type'])

    # Train-test split (stratified for imbalance)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # 2. Handle Imbalance with SMOTE
    smote = SMOTE(random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

    # 3. GridSearchCV for Hyperparameter Tuning
    param_grid = {
        'n_estimators': [200, 500],
        'max_depth': [10, 15, None],
        'min_samples_leaf': [2, 5, 10]
    }

    rf = RandomForestClassifier(random_state=42, class_weight='balanced_subsample')

    # Use f1 as scoring to balance precision and recall
    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)
    grid_search.fit(X_train_res, y_train_res)

    best_model = grid_search.best_estimator_
    print(f"Best Parameters: {grid_search.best_params_}")

    # 4. Validation (CV and Test Set)
    # Perform CV on the resampled training data to check stability
    cv_scores = cross_val_score(best_model, X_train_res, y_train_res, cv=5, scoring='recall')
    cv_std = np.std(cv_scores)

    # Evaluate on original test set
    y_pred = best_model.predict(X_test)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print("\n--- Model Performance ---")
    print(f"CV Recall Std Dev: {cv_std:.4f} (Target < 0.03)")
    print(f"Test Set Recall:   {recall:.4f} (Target > 0.85)")
    print(f"Test Set F1-Score: {f1:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # 5. Save Artifacts
    joblib.dump(best_model, 'maintenance_model.joblib')
    joblib.dump(le, 'label_encoder.joblib')
    print("Model and Label Encoder saved.")

    # 6. Visual Diagnostics
    # Precision-Recall Curve
    display = PrecisionRecallDisplay.from_estimator(best_model, X_test, y_test)
    plt.title("Precision-Recall Curve (Optimized Model)")
    plt.savefig('precision_recall_curve.png')
    plt.close()

    # Feature Importance
    importances = best_model.feature_importances_
    features = X.columns
    indices = np.argsort(importances)

    plt.figure(figsize=(10, 8))
    plt.title('Feature Importances')
    plt.barh(range(len(indices)), importances[indices], color='b', align='center')
    plt.yticks(range(len(indices)), [features[i] for i in indices])
    plt.xlabel('Relative Importance')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    plt.close()

if __name__ == "__main__":
    train_maintenance_model('datasets/ai4i2020.csv')
